# ============================ 최종 안전버전 서버 코드 (예외처리 강화 + 안정성 보완) =============================

from fastapi import FastAPI, UploadFile, File, HTTPException, Depends
from fastapi.security import OAuth2PasswordBearer
from jose import jwt
import openai
import os
import uuid
import shutil
from datetime import datetime, timedelta
from faster_whisper import WhisperModel
import asyncio
import re
import redis
import json

# ============================ 기본 설정 =============================

SECRET_KEY = "your_secret_key"
ALGORITHM = "HS256"
ACCESS_TOKEN_EXPIRE_MINUTES = 4320
oauth2_scheme = OAuth2PasswordBearer(tokenUrl="token")

openai.api_key = "sk-너희_OpenAI_API_KEY"
GPT_MODEL = "gpt-3.5-turbo-0125"

model = WhisperModel("base")

UPLOAD_DIR = "temp_uploads"
os.makedirs(UPLOAD_DIR, exist_ok=True)

# Redis 설정
try:
    redis_client = redis.Redis(host='localhost', port=6379, db=0, decode_responses=True)
    redis_client.ping()
except redis.exceptions.ConnectionError:
    raise RuntimeError("Redis 서버에 연결할 수 없습니다. 실행 중인지 확인하세요.")

app = FastAPI()

# ============================ 유틸리티 =============================

def safe_delete(file_path):
    try:
        os.remove(file_path)
    except Exception as e:
        print(f"[삭제 실패] {e}")

def verify_token(token: str = Depends(oauth2_scheme)):
    try:
        payload = jwt.decode(token, SECRET_KEY, algorithms=[ALGORITHM])
        user_id = payload.get("sub")
        if user_id is None:
            raise HTTPException(status_code=401, detail="Invalid token: no user_id")
        return user_id
    except jwt.JWTError as e:
        raise HTTPException(status_code=401, detail=f"Token decode error: {str(e)}")
    except Exception:
        raise HTTPException(status_code=401, detail="Invalid token")

# Redis 버퍼 저장
def store_buffer(user_id, text, timestamp, file_path):
    try:
        entry = json.dumps({"text": text, "timestamp": timestamp.isoformat(), "file": file_path})
        redis_client.rpush(f"buffer:{user_id}", entry)
        redis_client.set(f"last_time:{user_id}", timestamp.isoformat())
    except redis.exceptions.ConnectionError as e:
        raise HTTPException(status_code=500, detail=f"Redis 저장 오류: {str(e)}")

def get_buffer(user_id):
    try:
        items = redis_client.lrange(f"buffer:{user_id}", 0, -1)
        return [json.loads(i) for i in items]
    except redis.exceptions.ConnectionError as e:
        raise HTTPException(status_code=500, detail=f"Redis 조회 오류: {str(e)}")

def clear_buffer(user_id):
    try:
        redis_client.delete(f"buffer:{user_id}")
        redis_client.delete(f"last_time:{user_id}")
    except redis.exceptions.ConnectionError as e:
        print(f"[경고] Redis clear 실패: {str(e)}")

def buffer_ready(user_id):
    try:
        count = redis_client.llen(f"buffer:{user_id}")
        time_str = redis_client.get(f"last_time:{user_id}")
        if not time_str:
            return False
        last_time = datetime.fromisoformat(time_str)
        return count >= 30 or (datetime.now() - last_time > timedelta(hours=6))
    except redis.exceptions.ConnectionError as e:
        raise HTTPException(status_code=500, detail=f"Redis 연결 오류: {str(e)}")

# ============================ GPT 분석 함수 =============================

async def summarize_and_judge(texts):
    prompt = f"""
다음 대화를 감정 중심으로 간단히 요약하고,
이 대화가 \"연인 간 대화\"일 확률을 0에서 100 사이의 숫자로 추정하세요.

판단 기준:
- 애칭 사용
- 강한 감정 표현
- 미래 계획 공유
- 신체적 친밀 표현
- 이성 간 호감 감정

출력 형식:
요약: [요약 내용]
판단: xx% (숫자만)

대화:
{' '.join(texts)}
    """
    try:
        response = await asyncio.to_thread(openai.ChatCompletion.create,
            model=GPT_MODEL,
            messages=[{"role": "user", "content": prompt}],
            temperature=0.2,
            timeout=30
        )
        content = response.choices[0].message.content.strip()
        match = re.search(r"판단[:\s]+(\d{1,3})%", content)
        try:
            score = int(match.group(1)) if match else 0
        except:
            score = 0
        return score, content
    except Exception as e:
        print(f"[에러] GPT 요약+판별 실패: {e}")
        return 0, None

# ============================ 분석 프로세스 =============================

async def process_batch(user_id):
    try:
        buffer_items = get_buffer(user_id)
        if not buffer_items:
            print(f"[스킵] {user_id} - 분석할 데이터 없음")
            return

        texts_to_summarize = [item['text'] for item in buffer_items]
        판단, 요약결과 = await summarize_and_judge(texts_to_summarize)

        if 요약결과:
            if 판단 >= 70:
                print(f"[전송됨] {user_id} 요약 (연인 확률 {판단}%): {요약결과}")
            else:
                print(f"[삭제] {user_id} 연인 아님 확률 {100 - 판단}%")

        for item in buffer_items:
            safe_delete(item['file'])

        clear_buffer(user_id)

    except Exception as e:
        print(f"[에러] process_batch 실패: {e}")

# ============================ 업로드 API =============================

@app.post("/upload-audio")
async def upload_audio(file: UploadFile = File(...), token: str = Depends(oauth2_scheme)):
    try:
        user_id = verify_token(token)

        save_path = f"{UPLOAD_DIR}/{uuid.uuid4().hex[:10]}_{file.filename}"
        with open(save_path, "wb") as buffer:
            shutil.copyfileobj(file.file, buffer)

        try:
            result = await asyncio.to_thread(model.transcribe, save_path)
            if isinstance(result, tuple):
                segments, info = result
            else:
                segments = result
                info = None
        except Exception as e:
            raise HTTPException(status_code=500, detail=f"Whisper 변환 오류: {e}")

        text = " ".join(segment.text for segment in segments)

        now = datetime.now()
        store_buffer(user_id, text, now, save_path)

        if buffer_ready(user_id):
            await process_batch(user_id)

        return {"message": "녹음 수신 완료 및 저장"}

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"서버 오류: {e}")
